---
title: Working with RMC-BestFit
---

import NavContainer from "@site/src/components/NavContainer";
import VersionSelector from "@site/src/components/VersionSelector";
import Link from "@docusaurus/Link";
import addBaseUrl from "@docusaurus/useBaseUrl";
import Figure from "@site/src/components/Figure";
import FigReference from "@site/src/components/FigureReference";
import Citation from "@site/src/components/Citation";
import CitationFootnote from "@site/src/components/CitationFootnote";
import Equation from "@site/src/components/Equation";
import EquationReference from "@site/src/components/EquationReference";
import EquationNoRef from "@site/src/components/EquationNoRef";
import TableVertical from "@site/src/components/TableVertical";
import TableReference from "@site/src/components/TableReference";

<NavContainer
  link="/desktop-applications/rmc-bestfit"
  linkTitle="RMC-BestFit"
  document="desktop-applications/rmc-bestfit/users-guide"
/>

# Working with RMC-BestFit

In this quick start guide, we will demonstrate how to create a project, enter input data, select a model using the distribution fitting analysis, and
perform a Bayesian estimation analysis.

## Create a Project

To begin, let’s create a new project. When you open RMC-BestFit, a **Blank Project** file is automatically created, as shown
in <FigReference figKey="rmcbestfit-blank-project" />. The blank project is stored in your local temp directory. You may begin working with the blank
project file immediately.

<Figure
  figKey="rmcbestfit-blank-project"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure43.png"
  alt="RMC-BestFit Blank Project."
  caption="RMC-BestFit Blank Project."
/>

To save changes to the blank project, click the **Save** button on the tool bar or under the File menu. This will open the **Save Project As…**
prompt. Enter the desired file name and click the save button in the bottom right. Now you are ready to continue working with RMC-BestFit.

<Figure
  figKey="save-project-as"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure44.png"
  alt="Save Project As…."
  caption="Save Project As…."
/>

A new project can also be created by clicking **New Project…** under the File menu, or by clicking the New Project button located on the tool bar as
shown in <FigReference figKey="create-new-project-file-menu" /> and <FigReference figKey="create-new-project-tool-bar" />. If this is the first time
you're using RMC-BestFit, your recent projects list will be empty.

<Figure
  figKey="create-new-project-file-menu"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure45.png"
  alt="Create New Project from the File Menu."
  caption="Create New Project from the File Menu."
/>

<Figure
  figKey="create-new-project-tool-bar"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure46.png"
  alt="Create New Project from the Tool Bar."
  caption="Create New Project from the Tool Bar."
/>

The project properties will be shown in the **Properties Window**, which is typically located on the right-hand side of the main window. You may edit
the project name and description.

<Figure
  figKey="project-properties"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure47.png"
  alt="Project Properties."
  caption="Project Properties."
/>

## Input Data

In RMC-BestFit, the input data must be entered as block annual maxima, which are assumed to be independent and identically distributed (iid).
RMC-BestFit supports three different data types:

1. <u>Systematic Data</u>: Data that are collected at regular, prescribed intervals under a defined protocol. In a maximum likelihood context, these 
values are treated as exact measurements. Low outlier tests can be performed on the systematic data to ensure homogeneity.
2. <u>Interval Data</u>: Data whose magnitudes are not known exactly, but are known to fall within a range or interval. In a maximum likelihood context, 
these values are treated as interval-censored.
3. <u>Perception Thresholds</u>: Data points that occurred during a period of years and have magnitudes that are below a threshold value, but unknown 
by how much. In a maximum likelihood context, these values are treated as left-censored.

The Distribution Fitting Analysis chapter provides greater detail on how these data types are treated in a likelihood context.

### Create New Input Data

Let’s begin by creating a new input dataset. Right-click on the **Input Data** folder header and click **Create New…** as shown
in <FigReference figKey="create-new-input" />. Next, give the **Input Data** a name and click **OK**.

<Figure
  figKey="create-new-input"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure48.png"
  alt="Create New Input Data."
  caption="Create New Input Data."
/>

Once the new **Input Data** is created, it will be automatically opened into the **Tabbed Documents** area, and the input data properties will be
displayed in the **Properties Window**. From here, you can set the **Description**, **Unit Label**, **Plotting Position Parameter**, and perform a
**Low Outlier Test**.

For this example, we will be using 3-day inflow volumes for Blakely Mountain Dam, which is located near Hot Springs, Arkansas. This dataset includes
systematic data, historical data dating back to 1870, and paleoflood information dating back 5,000 years. As shown in <FigReference figKey="input-data-properties" />,
set the **Unit Label** to be “3-Day Flow (CFS)” and you will notice that this automatically updates the Y-axis labels on the **Chronology** and
**Frequency** plots.

<Figure
  figKey="input-data-properties"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure49.png"
  alt="Input Data Properties."
  caption="Input Data Properties."
/>

### Systematic Data

Systematic data are collected at regular, prescribed intervals under a defined protocol. In a maximum likelihood context, these values are treated as
exact measurements. The systematic dataset for Blakely Mountain Dam is provided in <TableReference tableKey="systematic-dataset-of" />. Note that the
systematic data does not need to be continuous; e.g., the Blakely Mountain dataset has missing data from 1931 to 1935. Gaps in data can be accounted
for using thresholds, which will be demonstrated later in the Perception Thresholds section.

To enter data, first click the **Add Row(s)** button located on the left side of the table tool bar. This will add a blank row to the bottom of the
table. Next, you can either manually enter your dataset, or copy and paste the dataset into the table as shown
in <FigReference figKey="paste-data-into" />. Once you have entered all of the data, you will see that the plotting positions are automatically
calculated and the data is plotted in the **Chronology** and **Frequency** plot as illustrated in <FigReference figKey="systematic-data" />.

<Figure
  figKey="add-systematic-data"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure50.png"
  alt="Add Systematic Data."
  caption="Add Systematic Data."
/>

<TableVertical
  tableKey="systematic-dataset-of"
  headers={
    [
      [ 
        {value: "Year"}, 
        {value: "Flow (CFS)"}, 
        {value: "Year"}, 
        {value: "Flow (CFS)"}, 
        {value: "Year"}, 
        {value: "Flow (CFS)"}
      ]
    ]
  }
  columns={[
    [
      "1923", "1924", "1925", "1926", "1927", "1928", "1929", "1930",
      "1936", "1937", "1938", "1939", "1940", "1941", "1942", "1943",
      "1944", "1945", "1946", "1947", "1948", "1949", "1950", "1951",
      "1952", "1953", "1954", "1955", "1956", "1957", "1958"
    ],
    [
      "57,985", "14,607", "8,403", "23,479", "66,629", "30,925", "25,046", "37,772",
      "9,074", "21,382", "43,769", "50,678", "7,360", "15,617", "23,189", "12,637",
      "30,064", "52,914", "22,607", "14,191", "19,098", "35,383", "25,046", "13,355",
      "20,330", "25,701", "26,897", "20,019", "18,240", "21,084", "28,886"
    ],
    [
      "1959", "1960", "1961", "1962", "1963", "1964", "1965", "1966",
      "1967", "1968", "1969", "1970", "1971", "1972", "1973", "1974",
      "1975", "1976", "1977", "1978", "1979", "1980", "1981", "1982",
      "1983", "1984", "1985", "1986", "1987", "1988", "1989"
    ],
    [
      "17,032", "45,014", "12,637", "17,037", "9,074", "36,066", "15,261", "23,886",
      "22,432", "55,536", "43,938", "22,490", "26,955", "53,417", "36,920", "42,584",
      "39,587", "12,996", "30,294", "8,952", "28,109", "12,637", "15,142", "16,624",
      "81,464", "13,952", "40,946", "29,317", "24,930", "42,076", "26,551"
    ],
    [
      "1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997",
      "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005",
      "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013",
      "2014", "2015", "2016", "2017", "2018"
    ],
    [
      "30,122", "32,586", "34,357", "32,586", "45,065", "29,547", "14,310", "44,107",
      "15,676", "18,922", "17,981", "40,097", "42,471", "17,451", "14,964", "20,798",
      "19,157", "33,729", "58,319", "35,041", "32,700", "35,212", "34,585", "46,921",
      "15,795", "42,189", "55,982", "34,585", "48,324"
    ]
  ]}
  fullWidth={false}
  alt="Systematic Dataset of 3-Day Inflows at Blakely Mountain Dam near Hot Springs, Arkansas."
  caption="Systematic Dataset of 3-Day Inflows at Blakely Mountain Dam near Hot Springs, Arkansas."
/>

<Figure
  figKey="paste-data-into"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure51.png"
  alt="Paste Data into Table."
  caption="Paste Data into Table."
/>

<Figure
  figKey="systematic-data"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure52.png"
  alt="Systematic Data."
  caption="Systematic Data."
/>

You can view the data as a chronology plot or as a frequency plot by toggling the radio buttons located underneath the plot as shown
in <FigReference figKey="view-chronology-or" />. Clicking the **Chronology Plot** radio button will display the data in chronological order, with
the years on the X-axis. The **Frequency Plot** radio button will display the data as a nonparametric frequency plot based on the Hirsch-Stedinger
plotting positions.

<Figure
  figKey="view-chronology-or"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure53.png"
  alt="View Chronology or Frequency Plot."
  caption="View Chronology or Frequency Plot."
/>

#### Data Table Features

You can edit the data table by using the tool bar located above the table, or by right-clicking within the table. You can interact with the table in
the following ways:

- Add rows(s) to the bottom of the table.
- Insert row(s) into the table.
- Delete row(s) from the table.
- Select all table cells.
- Copy the selected cells.
- Copy the selected cells with the table headers.
- Paste from the clipboard into the table.
- Sort a column in ascending or descending order.
- Clear all table sorting.

You can sort a column by right-clicking on the column header as shown below.

<Figure
  figKey="sort-input-data"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure54.png"
  alt="Sort Input Data Tables."
  caption="Sort Input Data Tables."
/>

#### Data Validation

The input data tables have built-in validation. The **Systematic Data** have the following requirements:

- The year must be unique.
- The year must be between -100,000 and +100,000.
- The value must be non-negative, or greater than or equal to zero.

When you enter invalid data, the table cell will turn red, and provide a tooltip indicating the source of the error. In addition, an error message
will appear in the **Message Window** indicating that you must resolve all errors in the data table.

<Figure
  figKey="input-data-validation"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure55.png"
  alt="Input Data Validation."
  caption="Input Data Validation."
/>

#### Plotting Positions

The input data can be plotted as a **Chronology Plot** or as a nonparametric **Frequency Plot** as shown in <FigReference figKey="view-chronology-or" />.
A _frequency plot_ or _probability plot_ is a plot of magnitude versus a probability. The probability assigned to each data point is commonly
determined using a _plotting position_ formula. Plotting positions are a method for creating an _empirical frequency_. The formula computes the
exceedance probability of a data point based on the rank of the data point in a sample of a given size. The plotting positions typically have
significant uncertainty due to sampling error resulting from small sample sizes.

A rank-order method is used to plot the annual maxima data. This involves ordering the data from the largest event to the smallest event, assigning a
rank of 1 to the largest event and a rank of _n_ to the smallest event, and using the rank (_i_) of the event to obtain a probability plotting
position. Many plotting position formulae are special cases of the general formula:

<Equation 
  equationKey="general-formula"
  equation="P_i = \frac{i - α}{n + 1 - 2a}" />

where _i_ is the rank of the event, _n_ is the sample size, _α_ is a constant greater than or equal to 0 and less than 1, and _P<sub>i</sub>_ is the exceedance
probability for an event with rank _i_. The value of determines how well the calculated plotting positions will fit a given theoretical probability
distribution.

RMC-BestFit uses the Hirsch-Stedinger (H-S) plotting position formula <Citation citationKey="HirschStedinger1987" /> <Citation citationKey="USGS2018" />,
which is an extension of the general formula above that is also capable of incorporating threshold-censored data. The H-S plotting positions are
used to visually and quantitatively assess the goodness-of-fit of the fitted distributions (see the Goodness-of-Fit Measures section for more detail).

You can choose from the following parameter options:

- Weibull (α = 0.0): Recommended as the default value because it is unbiased for all distributions.
- Median (α = 0.3175): Provides median exceedance probabilities for all distributions.
- Blom (α = 0.375): Recommended for Normal, Gamma, 2-parameter Log-Normal, 3-parameter Log-Normal, and Log-Pearson Type III distributions.
- Cunnane (α = 0.40): Recommended for Generalized Extreme Value and Log-Gumbel distributions, approximately quantile unbiased.
- Gringorten (α = 0.44): Recommended for Exponential, Gumbel and Weibull distributions.
- Hazen (α = 0.50): Recommended when the parameters of the parent distribution are unknown.

As you can see, each plotting position parameter has a different motivation. Some attempt to achieve unbiasedness in quantile estimates across
multiple distributions, while other formulas are optimized for use with a particular theoretical probability distribution. Choosing a plotting
position parameter is similar to choosing a probability distribution to represent a particular set of data. It is often better to select a plotting
position parameter that is flexible and makes the fewest assumptions. For this reason, the Weibull parameter (is set as the default value in
RMC-BestFit, which is consistent with current practice.

When you hover over the plotting position drop-down, you will see a tooltip providing the recommended use for the given parameter as shown below.

<Figure
  figKey="set-plotting-position"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure56.png"
  alt="Set Plotting Position Parameter."
  caption="Set Plotting Position Parameter."
/>

#### Low Outlier Test

For the distribution fitting or Bayesian estimation analyses to be theoretically valid, the input data must be independent and identically
distributed. As a means to ensure homogeneity, RMC-BestFit provides the Multiple Grubbs-Beck test (MGBT) <Citation citationKey="Cohn2013" /> for
low outliers, which is consistent with the Bulletin 17C guidelines <Citation citationKey="usgs2018" />. In RMC-BestFit, the MGBT is only applied
to systematic data, which are considered exact measurements. Interval- and threshold-censored data are not included in the test.

To run the MGBT, make sure the **Multiple Grubbs-Beck Test** checkbox is checked, and click the **Run Test** command button. When the test is
complete, a message box will appear that reports how many low outliers were identified. In addition, the MGBT Critical Value will be displayed in the
**Threshold Value** textbox. There should be zero low outliers identified for this dataset, so the threshold value should also be set to zero as shown
in <FigReference figKey="run-multiple-grubbsbeck" />.

<Figure
  figKey="run-multiple-grubbsbeck"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure57.png"
  alt="Run Multiple Grubbs-Beck Low Outlier Test."
  caption="Run Multiple Grubbs-Beck Low Outlier Test."
/>

If desired, you also have the option to enter a value for the low outlier threshold. When you run the test, any data value below this threshold will
be identified as a low outlier. The **Threshold Value** cannot be set to a value that would censor more than 50 percent of the values within the data
set. To use this option, uncheck the **Multiple Grubbs-Beck Test** checkboxand enter the preferred value.

Values that are identified as low outliers will be checked in the Is Low Outlier column of the systematic data table. The low outliers will be
displayed as a red <strong style={{ color: 'red' }}>X</strong> in the chronology and frequency plots.

The low outlier threshold value identified by the MGBT or manual threshold value is automatically treated as a left-censored threshold in the
distribution fitting and Bayesian estimation analyses. For example, if thelow outlier threshold value is 8,000 and there are eight data points below
the threshold identified as low outliers, then this is treated equivalent to a left-censored threshold with eight values below and zero above.
However, RMC-BestFit does not include the low outlier threshold in the H-S plotting position routine. Conceptually, the low outlier test removes exact
data points and replaces them with a threshold-censored value. This represents a loss in information. However, if this low outlier threshold is
included in the H-S routine, then it will make the plotting positions rarer, signaling an increase in information. This is counterintuitive, and for
this reason RMC-BestFit does not include the low outlier threshold in the H-S plotting position routine.

### Interval data

Interval data have magnitudesthat are not known exactly, but are known to fall within a range or interval. A paleoflood study was performed for the
Blakely Mountain watershed, where two major historical floods were identified: one occurred in 1882 and another occurred sometime around the year 1020.

<TableVertical
  tableKey="interval-data-for"
  headers={
    [
      [ 
        {value: "Year"}, 
        {value: "Lower"}, 
        {value: "Most Likely"}, 
        {value: "Upper"},
      ]
    ]
  }
  columns={[
    ["1020", "1882"],
    ["105,000", "66,000"],
    ["110,000", "76,000"],
    ["115,000", "86,000"]
  ]}
  fullWidth={false}
  alt="Interval Data for 3-Day Inflows at Blakely Mountain Dam near Hot Springs, Arkansas."
  caption="Interval Data for 3-Day Inflows at Blakely Mountain Dam near Hot Springs, Arkansas."
/>

You can add the interval data in the same manner as was done for the systematic data. First click the **Add Row(s)** button located on the left side
of the table tool bar. This will add a blank row to the bottom of the interval data table. Next, you can either manually enter the data, or copy and
paste the interval data into the table. Once you have entered the data, you will see that the plotting positions are automatically calculated and the
intervals are plotted in the **Chronology** and **Frequency** plot as vertical bars (see <FigReference figKey="interval-data" />).

<Figure
  figKey="interval-data"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure58.png"
  alt="Interval Data."
  caption="Interval Data."
/>

The **Interval Data** have the following requirements:

- The year must be unique.
- The year must be between -100,000 and +100,000.
- The year cannot overlap with any data point in the **Systematic Data** table.
- The lower, most likely, and upper values must be non-negative, or greater than or equal to zero.
- The lower must be less than the most likely value, and the upper must be greater than the most likely value.

### Perception Thresholds

The term _perception threshold_ originates from Bulletin 17C (U.S. Geological Survey, 2018). For the purposes of RMC-BestFit, a **Perception Threshold**
defines a threshold level over a period of years. Data points that occurred during the threshold period have magnitudes that are below the threshold
value, but it is unknown by how much. Conversely, we can also say that if an event occurred during the threshold period, and it had a magnitude larger
than the threshold value, then we would have evidence it occurred; i.e., data points larger than the threshold would have been _perceived_ by us.

There were four perception thresholds identified for the Blakely Mountain Dam 3-day inflow volume dataset (see <TableReference tableKey="threshold-data-for" />).
The paleoflood study determined that 3-day inflows have not exceeded 220,000 cfs in the last ~5,000 years. Flood volumes did not exceed 104,000 cfs
during the years between the paleoflood in 1019 and 1869. From 1870 to the 1922, which is the beginning of the systematic dataset, 3-day flood volumes
did not exceed 65,000 cfs, except for the large 1882 event. Finally, 3-day flood volumes during the missing years of systematic data from 1931 to 1935,
also did not exceed 65,000 cfs.

<TableVertical
  tableKey="threshold-data-for"
  headers={
    [
      [ 
        {value: "Start Year"}, 
        {value: "End Year"}, 
        {value: "Value"}, 
      ]
    ]
  }
  columns={[
    ["-2890", "1019", "1870", "1931"],
    ["1018", "1869", "1922", "1935"],
    ["220,000", "104,000", "65,000", "65,000"]
  ]}
  fullWidth={false}
  alt="Threshold Data for 3-Day Inflows at Blakely Mountain Dam near Hot Springs, Arkansas."
  caption="Threshold Data for 3-Day Inflows at Blakely Mountain Dam near Hot Springs, Arkansas."
/>

Threshold data is entered in the same manner as was done for the systematic and interval data. Click the **Add Row(s)** button located on the left
side of the table tool bar. Next, you can either manually enter the data, or copy and paste the threshold data into the table. Once you have entered
the data, you will see that the plotting positions are automatically calculated and the thresholds are plotted in the **Chronology** plot as a shaded
area (see <FigReference figKey="perception-thresholds" />).

<Figure
  figKey="perception-thresholds"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure59.png"
  alt="Perception Thresholds."
  caption="Perception Thresholds."
/>

The **Perception Threshold Data** have the following requirements:

- The start and end years must be between -100,000 and +100,000.
- The start year must be less than or equal to the end year.
- The start and end years of the thresholds must be entered in ascending order.
- The threshold periods cannot overlap with each other.
- The threshold values must be non-negative, or greater than or equal to zero.

### Summary Statistics

RMC-BestFit provides summary statistics for the systematic data and for all of the data, including low outliers, intervals, and perception thresholds
(see <FigReference figKey="input-data-summary" />). Summary statistics for the systematic data are based on the sample moments and percentile
estimates, while summary statistics for all data are based on the nonparametric H-S plotting positions. The central moments of the nonparametric
distribution are estimated using numerical integration. The nonparametric distribution functions are provided in <EquationReference equationKey="non-parametric-distribution-1" />
to <EquationReference equationKey="non-parametric-distribution-3" />. Percentiles are estimated using the inverse cumulative distribution function
as shown in <EquationReference equationKey="non-parametric-distribution-3" />.

<Equation
  equationKey="non-parametric-distribution-1"
  equation= "f(x) = \frac{p_{i+1} - p_i}{x_{i+1} - x_i}"
/>

where <EquationNoRef equation="f(x)" /> is the probability density function (PDF) of the variable <EquationNoRef equation="X" />; there is an array of
continuous values <EquationNoRef equation="\{x\} = \{x_1, x_2, \ldots, x_n\}" /> for <EquationNoRef equation="x_i \leq x &lt; x_{i+1}" /> with
non-exceedance probabilities <EquationNoRef equation="\{p\} = \{p_1, p_2, \ldots, p_n\}" /> with <EquationNoRef equation="0 \leq p_i \leq 1" />.

<Equation 
  equationKey="non-parametric-distribution-2"
  equation= "F(x) = p_i + \left(p_{i+1} - p_i \right) \left(\frac{x - x_i}{x_{i+1} - x_i}\right)"
/>

<Equation 
  equationKey="non-parametric-distribution-3"
  equation="F^{-1}(p) = x_i + (x_{i+1} - x_i) \left( \frac{p - p_i}{p_{i+1} - p_i} \right)"
/>

where <EquationNoRef equation="F(x)" /> is the cumulative distribution function (CDF) of the variable <EquationNoRef equation="X" />
;<EquationNoRef equation="F^{-1}(p)" /> is the inverse CDF; and there is an array of continuous values <EquationNoRef equation="\{x\} = \{x_1, x_2, \ldots, x_n\}" />
for <EquationNoRef equation="x_i \leq x \leq x_{i+1}" /> with non-exceedance probabilities <EquationNoRef equation="\{p\} = \{p_1, p_2, \ldots, p_n\}" />
with <EquationNoRef equation="0 \leq p_i \leq 1" /> and <EquationNoRef equation="p_i \leq p \leq p_{i+1}" />.

The summary statistics provide a preview for what to expect when performing distribution fitting or Bayesian estimation. For example, in the case of
Blakely Mountain Dam, we can see that the inclusion of historical and paleoflood data slightly increased the skewness of the data. The systematic data
has a skewness (of log) of -0.2388; whereas the nonparametric analysis, which includes all of the data, has a skewness (of log) of -0.2151. We should
expect to see a similar behavior when fitting the Log-Pearson Type III distribution.

<Figure
  figKey="input-data-summary"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure60.png"
  alt="Input Data Summary Statistics."
  caption="Input Data Summary Statistics."
/>

## Distribution Fitting Analysis

The **Distribution Fitting Analysis** in RMC-BestFit uses the method of Maximum Likelihood Estimation (MLE) to fit several univariate probability
distributions to the user-specified **Input Data**. You can use the distribution fitting analysis results to inform model selection for use in the
Bayesian estimation analysis. For each fitted distribution, RMC-BestFit provides three goodness-of-fit measures: the Akaike Information Criteria
(AIC), the Bayesian Information Criteria (BIC), and Root-Mean Squared Error (RMSE). These measures indicate how well the distribution fits the input
data, with a smaller value representing a better fit.

To fit distribution with RMC-BestFit, there are four steps required:

- Define **Input Data**.
- Run the fitting analysis.
- Interpret the results.
- Select a distribution to use in the **Bayesian Estimation Analysis**.

Further details of these steps are discussed in the following sections.

### Create New Distribution Fitting Analysis

Let’s create a new **Distribution Fitting Analysis**. Right-click on the **Distribution Fitting Analysis** folder header and click **Create New…** as
shown in <FigReference figKey="create-new-distribution" />. Next, give the fitting analysis a name and click **OK**.

<Figure
  figKey="create-new-distribution"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure61.png"
  alt="Create New Distribution Fitting Analysis."
  caption="Create New Distribution Fitting Analysis."
/>

Once, the new **Distribution Fitting Analysis** is created, it will be automatically opened into the **Tabbed Documents** area, and the fitting
analysis properties will be displayed in the **Properties Window**. From here, you can set the **Description**, **Input Data, Output Frequency
Ordinates**, and **Fit Distributions**.

### Define Input Data

Click the **Input Data** drop-down and select the desired data for the fitting analysis as shown in <FigReference figKey="distribution-fitting-analysis-props" />.
You can set the **Output Frequency Ordinates** by clicking on the **Options** tab at the top of the **Properties Window** as shown
in <FigReference figKey="distribution-fitting-analysis-ordinates" />. The output frequency ordinates are the annual exceedance probabilities (AEP) used for
plotting the fitted distributions on the frequency plot. The default frequency ordinates range from 0.99 to 1E-6 AEP.

<Figure
  figKey="distribution-fitting-analysis-props"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure62.png"
  alt="Distribution Fitting Analysis Properties."
  caption="Distribution Fitting Analysis Properties."
/>

<Figure
  figKey="distribution-fitting-analysis-ordinates"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure63.png"
  alt="Distribution Fitting Analysis Output Frequency Ordinates."
  caption="Distribution Fitting Analysis Output Frequency Ordinates."
/>

### Run the Fitting Analysis

After you have selected the **Input Data**, click the **Fit Distributions** command button to run the distribution fitting analysis. The runtime
typically takes less than a second. When the analysis is complete, you will see a table of goodness-of-fit measures and all of the distributions
plotted on the **Frequency Plot** as shown in <FigReference figKey="distribution-fitting-analysis-results" />.

<Figure
  figKey="run-the-distribution"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure64.png"
  alt="Run the Distribution Fitting Analysis."
  caption="Run the Distribution Fitting Analysis."
/>

<Figure
  figKey="distribution-fitting-analysis-results"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure65.png"
  alt="Distribution Fitting Analysis Graphical Results."
  caption="Distribution Fitting Analysis Graphical Results."
/>

#### Maximum Likelihood Estimation (MLE)

In the distribution fitting analysis, parameters are estimated using the MLE method. The MLE method formulates a likelihood function using sample
data <EquationNoRef equation="D = (X_1, \dots, X_n)" /> and the parameters <EquationNoRef equation="θ" /> of the probability distribution, and
solves for the value of the parameters that maximize the likelihood function <Citation citationKey="Rao2000" /> <Citation citationKey="Jongejan2018" />.
The likelihood function gives the probability of the data conditional on the distribution parameters
(<EquationReference equationKey="likelihood-function" />).

<Equation
  equationKey="likelihood-function"
  equation="L_S(D \mid \theta) = \prod_{i=1}^{n_s} f(X_i \mid \theta)"
/>

where:

- <EquationNoRef equation="D" /> is the sample of systematically recorded annual discharge maxima <EquationNoRef equation="(X_1, \dots, X_{n_S})" />
- <EquationNoRef equation="f(∙)" /> is the probability density function (PDF) of the variable <EquationNoRef equation="X" />

Censored data can be incorporated into the MLE method by augmenting the likelihood function. Left-censored threshold data has the following likelihood function:

<Equation
  equationKey="log-likelihood-function"
  equation="L_L(D \mid \theta) = \prod_{i=1}^{n_L} \binom{h}{k} F(X_0 \mid \theta)^{h - k}"
/>

where <EquationNoRef equation="X_0" /> is the threshold; <EquationNoRef equation="h" /> is the threshold period; <EquationNoRef equation="k" /> is
the number of observations that exceeded the threshold during the period; <EquationNoRef equation="(h \mid k)" /> is the binomial coefficient;
and <EquationNoRef equation="F(∙)" /> is the cumulative distribution function (CDF) of the variable <EquationNoRef equation="X_0" />. The binomial
coefficient can be dropped from <EquationReference equationKey="log-likelihood-function" /> because it will be held constant
as <EquationNoRef equation="θ" /> is varied. Interval-censored data has the following likelihood function:

<Equation
  equationKey="interval-likelihood"
  equation="L_I(D \mid \theta) = \prod_{i=1}^{n_I} \left[ F(X_{U_i} \mid \theta) - F(X_{L_i} \mid \theta) \right]"
/>

where there are <EquationNoRef equation="n_I" /> observations known to lie between upper and lower bounds, <EquationNoRef equation="X_U" />
and <EquationNoRef equation="X_L" />. The overall likelihood function is then constructed by multiplying the components:

<Equation
  equationKey="combined-likelihood"
  equation="L(D \mid \theta) = L_S(D \mid \theta) \cdot L_L(D \mid \theta) \cdot L_I(D \mid \theta)"
/>

These likelihood formulations for censored data are consistent with those presented
in <Citation citationKey="Stedinger1983" />, <Citation citationKey="Kuczera1999" />, and <Citation citationKey="OConnell2002" />.

From the perspective of Bayesian estimation, MLE is a special case of _maximum a posteriori_ (MAP) that assumes a uniform prior distribution for each
model parameter. Therefore, if we assume uniform priors in the **Bayesian Estimation Analysis**, we will get the same posterior mode as the MLE method
used in the **Distribution Fitting Analysis** (any differences in results would be attributed to convergence errors).

RMC-BestFit uses the Nelder-Mead method (also commonly called the downhill simplex method or amoeba method) to perform MLE for every distribution. The
Nelder-Mead method finds the parameter set that maximizes the likelihood function using a direct search method.

### Interpret the Results

Once the **Distribution Fitting Analysis** is complete, you should evaluate the results. RMC-BestFit provides goodness-of-fit measures and comparison
graphs to help you evaluate the fits and select the best probability distribution to use in the **Bayesian Estimation Analysis**.

#### Goodness-of-Fit Measures

RMC-BestFit provides three goodness-of-fit measures: AIC, BIC, and RMSE. These measures indicate how well the distribution fits the input data, with a
smaller value representing a better fit. The goodness-of-fit statistics are used for two purposes: 1) _Model selection_ is the process of picking one
fitted distribution over another; 2) whereas, _fit validation_ is the process of determining whether a fitted distribution agrees well with the data.

AIC and BIC are used for model selection among a finite set of models (the term _model_ is synonymous with _probability distribution_). The model with
the lowest AIC or BIC is preferred. When comparing multiple models, additional parameters often yield larger, optimized log-likelihood values.AIC and
BIC penalize for more complex models, i.e., models with additional parameters. However, for BIC, the penalty is a function of the sample size, and so
it is typically more severe than that of AIC. The formulas for AIC and BIC are shown in <EquationReference equationKey="AIC" />
and <EquationReference equationKey="BIC" />, respectively. To address potential over-fitting, RMC-BestFit implements a correction for small sample
sizes for AIC.

<Equation 
  equationKey="AIC"
  equation="AIC = 2k - 2 \ln(\hat{L}) + \frac{2k^2 + 2k}{n - k - 1}" 
/>

<Equation 
  equationKey="BIC"
  equation="BIC = \ln(n)k - 2 \ln(\hat{L})" 
/>

where _k_ is the number of parameters; _n_ is the sample size; and _L̂_ is the maximum value of the likelihood function for the model.

RSME provides a measure for fit validation, with smaller values indicating a better fit. RMSE is computed based on how well the probability
distribution agrees with the plotting positions of the input data. You can set the plotting position parameter based on preference or theoretical
motives, so this measure has the potential to be biased. To minimize this issue, the default plotting position coefficient in the input data interface
is set to Weibull (α = 0), which is unbiased. The formula for RMSE is as follows:

<Equation 
  equationKey="RMSE"
  equation="RMSE = \sqrt{\frac{\sum_{i=1}^{n} (\hat{y}_i - y_i)^2}{n}}"
 />

where _n_ is the sample size; _ŷ<sub>i</sub>_ is the predicted value for item _i_; and _y<sub>i</sub>_ is the observed value for step <i>i</i>.

You can sort each column of the goodness-of-fit table in ascending or descending order by right-clicking the column header as shown
in <FigReference figKey="distribution-fitting-analysis-gof" />. As you move your cursor over the table, a tooltip will appear showing the fitted parameters
of the distribution as shown in <FigReference figKey="check-or-uncheck" />. You may check or uncheck distributions in this table to add or remove the
fitted distributions from the comparison plots.

<Figure
  figKey="distribution-fitting-analysis-gof"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure66.png"
  alt="Distribution Fitting Analysis Goodness-of-Fit Table."
  caption="Distribution Fitting Analysis Goodness-of-Fit Table."
/>

<Figure
  figKey="check-or-uncheck"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure67.png"
  alt="Check or Uncheck Distributions from the Goodness-of-Fit Table."
  caption="Check or Uncheck Distributions from the Goodness-of-Fit Table."
/>

#### Comparison Plots

RMC-BestFit provides five types of graphs to help you visually assess the quality of the distribution fits. A comparison graph plots the input data
and fitted distributions on the same graph, allowing you to visually compare them. The graphs allow you to determine whether the fitted distribution
matches the input data in critical areas. For example, for flood frequency analyses, it is important to have good agreement in the extreme, right-hand
tail of the distribution.

##### Frequency Plot

A **Frequency Plot** is a plot of magnitude versus annual exceedance probability (AEP). AEP is typically plotted on the X-axis using a Normal or
Gumbel probability scale to linearize the plot and exaggerate the extreme right-hand tail of the data. The frequency plot compares the fitted
distributions to the plotting positions of the input data as shown in <FigReference figKey="distribution-fitting-analysis-freq-plot" />.

For demonstration purposes, let’s only evaluate the three-parameter distributions. Uncheck all of the two-parameter distributions in the
goodness-of-fit table. Then sort the RMSE column in ascending order as shown in <FigReference figKey="distribution-fitting-analysis-freq-plot" />. We see that
the Log-Pearson Type III (LPIII) distribution provides the smallest RMSE. In addition, we can also see that it provides a very good fit through the
input data plotted in the **Frequency Plot**. The Pearson Type III (PIII) and Generalized Extreme Value (GEV) distributions also fit through the data
well and have a relatively small RSME.

<Figure
  figKey="distribution-fitting-analysis-freq-plot"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure68.png"
  alt="Distribution Fitting Analysis Frequency Plot."
  caption="Distribution Fitting Analysis Frequency Plot."
/>

##### PDF Plot

A **PDF Plot** compares the probability density function (PDF) of the fitted distribution to a histogram of the input data as shown
in <FigReference figKey="distribution-fitting-analysis-PDF-plot" />. The **Frequency Plot** and **PDF Plot** are usually the most informative comparisons. With
the PDF plot, it is easy to see the where the highest discrepancies are and whether the general shape of the data and fitted distributions agree well.
From the PDF plot, we can see that Generalized Pareto (GPA) distribution does not fit the data as well as the others.

<Figure
  figKey="distribution-fitting-analysis-PDF-plot"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure69.png"
  alt="Distribution Fitting Analysis PDF Plot."
  caption="Distribution Fitting Analysis PDF Plot."
/>

##### CDF Plot

The **CDF Plot** compares the cumulative distribution function (CDF) of the fitted distribution to the plotting positions of the input data as shown
in <FigReference figKey="distribution-fitting-analysis-CDF-plot" />. The CDF plot has a very insensitive scale, and is not very useful for comparing the
location, spread, and shape of the distributions, for which the PDF plot is much better. In many cases, the CDF plot will not provide a good visual
measure for the goodness-of-fit.

<Figure
  figKey="distribution-fitting-analysis-CDF-plot"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure70.png"
  alt="Distribution Fitting Analysis CDF Plot."
  caption="Distribution Fitting Analysis CDF Plot."
/>

##### P-P Plot

The Probability-Probability (P-P) plot graphs the F(x) of the model (distribution) versus the input data plotting positions. The closer the plot
resembles the diagonal 1:1 line, the better the fit. The **P-P Plot** can be useful if you are interested in closely matching cumulative percentiles
as it showsthe differences between the middle of the fitted distributions and the input data. From the P-P plot, we can see that the GPA distribution
has the poorest agreement with the data.

<Figure
  figKey="distribution-fitting-analysis-pp-plot"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure71.png"
  alt="Distribution Fitting Analysis P-P Plot."
  caption="Distribution Fitting Analysis P-P Plot."
/>

##### Q-Q Plot

The Quantile-Quantile (Q-Q) plot graphs the inverse CDF of the model versus the percentile values of the input data. Again, the closer the plot
resembles the diagonal 1:1 line, the better the fit. The **Q-Q Plot** can be useful if you are interested in closely matching cumulative percentiles
as it shows the differences between the tails of the fitted distributions and the input data. From the Q-Q plot, we can see that the PIII, LPIII, and
GEV distributions all fit the right-hand tail of the data really well. The Generalized Logistic (GLO) distribution has the poorest agreement with the
right-hand tail of the data, followed by the GPA distribution as the second least favorable fit.

<Figure
  figKey="distribution-fitting-analysis-qq-plot"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure72.png"
  alt="Distribution Fitting Analysis Q-Q Plot."
  caption="Distribution Fitting Analysis Q-Q Plot."
/>

#### Tabular Results

RMC-BestFit reports the parameters and basic statistics (mean, standard deviation, skewness, etc.) for each of the fitted distributions, which can
also be compared to the same statistics for the input data. Quantiles for the specified output frequency AEPs are also provided in the **Tabular
Results**.

<Figure
  figKey="distribution-fitting-analysis-tab-results"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure73.png"
  alt="Distribution Fitting Analysis Tabular Results."
  caption="Distribution Fitting Analysis Tabular Results."
/>

### Selecting a Probability Distribution

Finally, you need to select a probability distribution to carry forward to the **Bayesian Estimation Analysis**. The following steps can help you
choose an appropriate distribution:

- Start by reviewing the descriptions of the probability distributions found in the Appendix. Then, look at the variable in question. Does the data have
  bounds? Is it symmetric or skewed? Which distributions are theoretically appropriate for the data?
- Select candidate distributions that best characterize the variable.
- Then, use the **Distribution Fitting Analysis** results to select the distribution that best describes your **Input Data**.

In the above example, we evaluated how well the three-parameter distributions fit 3-day inflow data at Blakely Mountain Dam. It was clear that the
PIII, LPIII, and GEV distributions produced better fits than the GLO and GPA distributions. Flow data can span several orders in magnitude (e.g.,
1,000 cfs to 1,000,000 cfs), and is typically skewed and cannot have negative values. If the skewness of the data is greater than the absolute value
of 2 (<EquationNoRef equation="C_s > \lvert 2 \rvert"/>), then the maximum likelihood estimation method cannot produce a solution for the PIII and
LPIII distributions. Real-space flow data can often have skews much larger than 2. Therefore, LPIII better characterizes flow data than the PIII
distribution <Citation citationKey="USGS1982" /> <Citation citationKey="USGS2018" />. As such, the PIII distribution is not considered appropriate for
characterizing the flow data.

When considering the statistical and graphical goodness-of-fit performance, and the appropriateness of the distribution, the LPIII distribution fits
the **Input Data** the better than the GEV distribution. The LPIII distribution will now be carried forward to the Bayesian estimation analysis.

## Bayesian Estimation Analysis

RMC-BestFit performs Bayesian estimation using a Markov Chain Monte Carlo (MCMC) algorithm to estimate distribution parameters given the specified
input data and parent distribution. The Bayesian estimation method produces the most likely estimate for parameters (posterior mode) and a
characterization of the parameter uncertainty.

To perform Bayesian Estimation with RMC-BestFit, there are four steps required:

- Define **Input Data** and select the parent probability distribution.
- Run the **Bayesian Estimation Analysis**.
- Diagnose convergence.
- Explore the results.

Further details of these steps are discussed in the following sections.

### Create New Bayesian Analysis

Let’s create a new **Bayesian Estimation Analysis**. Right-click on the **Bayesian Estimation Analysis** folder header and click **Create New…** as
shown in <FigReference figKey="create-new-distribution" />. Next, give the Bayesian analysis a name and click **OK**.

<Figure
  figKey="create-new-bayesian"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure74.png"
  alt="Create New Bayesian Estimation Analysis."
  caption="Create New Bayesian Estimation Analysis."
/>

Once, the new **Bayesian Estimation Analysis** is created, it will be automatically opened into the **Tabbed Documents** area, and the Bayesian
analysis properties will be displayed in the **Properties Window**. From here, you can set the required inputs.

### Bayesian Analysis Framework

In Bayesian analysis, the values of the parent probability distribution parameters <EquationNoRef equation="θ = (θ₁, θ₂, …, θₚ)"/> converge to
a distribution rather than to a single best value. The uncertainty in the parameters is represented by a prior probability
distribution <EquationNoRef equation="P(θ)"/>, which is established based on information available a priori. This prior distribution is not
derived from the observed data <EquationNoRef equation="D = (X₁, …, Xₙ)"/>, but instead comes from other sources that can be either subjective
(e.g., expert opinion) or objective (e.g., previous statistical analyses, or regional information). After the prior distributions and the observed
data are specified, Bayes’ theorem (<EquationReference equationKey="bayes-theorem" />) is used to combine the a priori information about the parameters
with the observed data, using the likelihood <EquationNoRef equation="P(D | θ)"/> (<EquationReference equationKey="likelihood-data" />).

<Equation
  equationKey="bayes-theorem"
  equation="P(\theta \mid D) = \frac{P(D \mid \theta) \cdot P(\theta)}{\int P(D \mid \theta) \cdot P(\theta) \, d\theta}"
/>

<Equation
  equationKey="likelihood-data"
  equation="P(D \mid \theta) = \prod_{i=1}^{n} f(X_i \mid \theta)"
/>

where <EquationNoRef equation="P(θ | D)" /> is the posterior probability density function (PDF) of <EquationNoRef equation="θ"/>; <EquationNoRef equation="P(θ)"/>
is the prior PDF of <EquationNoRef equation="θ"/>; and <EquationNoRef equation="P(D | θ)"/> is the likelihood function. The posterior cumulative
distribution function (CDF) of <EquationNoRef equation="X"/> now follows from the total probability theorem:

<Equation
  equationKey="posterior-predictive"
  equation="F(X) = \int F(X \mid \theta, D) \cdot P(\theta \mid D) \, d\theta"
/>

which is a probability-weighted sum of the CDFs under different posterior parameter sets . <EquationReference equationKey="posterior-predictive" /> is known as
the Bayesian posterior predictive distribution and is equivalent to the _expected probability of exceedance_ concept first presented by <Citation citationKey="Beard1960" />.

<Citation citationKey="Stedinger1983" /> and <Citation citationKey="Kuczera1999" /> refer to this integral as the design flood distribution, and it 
is considered the optimal estimator of an exceedance probability.

In most cases, there is not a closed form solution to the denominator of <EquationReference equationKey="bayes-theorem" />. Therefore, Monte Carlo
simulation techniques such as Markov Chain Monte Carlo (MCMC) are required. The RMC-BestFit software employs an adaptive Differential Evolution Markov
Chain (DE-MC<sub>z</sub>) population-based sampler <Citation citationKey="terBraak2008" />, which has proven to be very efficient at arriving at the
posterior distribution.

<FigReference figKey="diagram-illustrating-the" /> illustrates the basic steps in Bayesian analysis. The Bayesian approach offers a framework that is
well suited to incorporate different sources of information, such as systematic records, historical data, regional information, and other information
along with related uncertainties <Citation citationKey="Viglione2013" />. The Bayesian approach allows you to formally include your own expertise
into the analysis by choosing _a priori_ distributions. The possibility to combine this information with the observed data is even more important
because, in practice, the observed records are usually of limited size.

<Figure
  figKey="diagram-illustrating-the"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure75.png"
  alt="Diagram Illustrating the Basic Steps in Bayesian Analysis (adapted from , which was originally taken  (Perreault, 2000))."
  caption="Diagram Illustrating the Basic Steps in Bayesian Analysis (adapted from , which was originally taken  (Perreault, 2000))."
/>

### Define Inputs

You must select the **Input Data** and the parent probability distribution to use in the **Bayesian Estimation Analysis**. The parent distribution
describes the parent population of your Input Data, which is assumed to be a sample from the parent population. By default, the parent distribution is
set as the Generalized Extreme Value (GEV) distribution.

To select your data, click the **Input Data** drop-down on the **General** tab and select the desired data for the Bayesian analysis as shown
in <FigReference figKey="bayesian-estimation-analysis-props" />. Next, set the parent distribution to be the distribution selected from the **Distribution
Fitting Analysis**, which in this case was Log-Pearson Type III (LPIII). The prior distributions for parameters and quantiles can also be set from the
**General** tab.

<Figure
  figKey="bayesian-estimation-analysis-props"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure76.png"
  alt="Bayesian Estimation Analysis General Properties."
  caption="Bayesian Estimation Analysis General Properties."
/>

#### Default Flat Priors

After you have selected the **Input Data** and parent distribution, RMC-BestFit automatically develops default flat (uniform) priors for the selected
distribution, given the data. The goal of this routine is to develop prior distributions that have minimal impact on the posterior distributions. This
approach is sometimes referred to as vague priors, or weakly informative priors. Weakly informative priors contain information to keep the posterior
within reasonable bounds without fully capturing one’s scientific knowledge about the underlying parameter <Citation citationKey="Gelman2014" />. There
are two approaches to developing a weakly informative prior as described by <Citation citationKey="Gelman2014" />:

1. Start with some version of an uninformative prior distribution and then add enough information so that inferences are constrained to be reasonable.
2. Start with a strong, highly informative prior and broaden it to account for uncertainty in one’s prior beliefs and in the applicability of any
   historically based prior distributions to new data.

RMC-BestFit develops default flat priors by first considering the parent distribution and parameter support, and then peeking at the data to determine
broad upper and lower constraints for the parameters. This ensures the prior distributions for parameters are somewhat centered near the likelihood,
but with a much larger spread. The typical end-user of RMC-BestFit will likely not have much advanced training in Bayesian statistics. Therefore, the
routine for default flat priors ensures you will get reasonable results out of the box.

The default flat priors are shown in <FigReference figKey="default-flat-prior" />. You may uncheck the **Use Default Flat Priors** checkbox to
customize the priors. See the Informative Priors section for details on how to set informative priors for parameters and quantiles.

<Figure
  figKey="default-flat-prior"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure77.png"
  alt="Default Flat Prior Distributions for Parameters."
  caption="Default Flat Prior Distributions for Parameters."
/>

#### Simulation Options

For typical applications, the default simulation options should provide reasonable results out of the box. The **Bayesian Estimation Analysis** has
the following simulation options (see <FigReference figKey="bayesian-estimation-analysis-sim-output-options" />) available for advanced users:

- **_Number of Chains_**: The **Bayesian Estimation Analysis** utilizes an adaptive Differential Evolution Markov Chain
  (DE-MC<sub>z</sub>) population-based sampler <Citation citationKey="terBraak2008" />, in which multiple chains are run in parallel. It is recommended
  that the number of chains be 2 times the number of parent distribution parameters.
- **_Thinning Interval_**: Determines how often the Markov Chain Monte Carlo (MCMC) evolutions will be recorded. Thinning can be used to reduce
  autocorrelation in the posterior distributions. A thinning interval of 20 means that every 20th iteration will be recorded.
- **_Warm Up Evolutions_**: The number of thinned warm up MCMC evolutions to discard at the beginning of the simulation. It is recommended that the warm
  up be half the length of the number of evolutions; e.g., if the number of evolutions is 4,000, then the warm up length should be 2,000.
- **_Evolutions_**: The number of thinned MCMC evolutions to simulate. If the thinning interval is 10 and the number of evolutions is 1,000, there will
  be a total of 10,000 iterations in the simulation. It is recommended to simulate at least 3,000 thinned evolutions.
- **_PRNG Seed_**: The pseudo random number generator (PRNG) seed used within the Monte Carlo simulation. The PRNG ensures repeatability.
- **_Initial Population_**: Determines the length of the initial population vector. It is recommended that the initial population be at least 100 times
  the number of parent distribution parameters in length.
- **_Jump Parameter (γ)_**: The jump parameter allows the simulation to jump from one mode region to another in the target distribution. It is recommended
  to set <EquationNoRef equation="\gamma = \frac{2.38}{\sqrt{2d}}" />, where is the number of parent distribution parameters.
- **_Jump Threshold_**: Determines how often the jump parameter (γ) switches to 1.0. It is recommended that the jump threshold be set to 0.20, which will
  result in adaptation 20% of the time.
- **_Noise Parameter (b)_**: A random noise is added to the proposal in the MCMC simulation. The noise follows a uniform distribution <EquationNoRef equation="U(-b, +b)" />.
  It is recommended that be very small, such as 0.001.

The simulation options are automatically set with default settings. You can uncheck the **Use Defaults** checkbox to customize the settings.

#### Output Options

The **Bayesian Estimation Analysis** has the following output options (see <FigReference figKey="bayesian-estimation-analysis-sim-output-options" />):

- **_Credible Interval_**: Sets the width of the credible interval. For a 90% credible interval, the value of interest lies with a 90% probability in
  the interval.
- **_Output Length_**: The number of posterior parameter sets to output. It is recommended to output 10,000 parameter sets to ensure an accurate 90%
  credible interval.
- **_Output Frequency Ordinates_**: The annual exceedance probabilities (AEP) used for plotting the results on the frequency plot.The default frequency
  ordinates range from 0.99 to 1E-6 AEP.

<Figure
  figKey="bayesian-estimation-analysis-sim-output-options"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure78.png"
  alt="Bayesian Estimation Analysis Simulation and Output Options."
  caption="Bayesian Estimation Analysis Simulation and Output Options."
/>

### Run the Bayesian Analysis

After you have defined all of your inputs and settings, click the **Estimate** command button to run the Bayesian analysis. The runtime typically
takes on the order of 30 seconds, depending on your computer configurations. A progress bar will appear to the left of the Estimate command button as
shown in <FigReference figKey="run-the-bayesian" />. When the analysis is complete, you will see the frequency curve with credible intervals appear in
**Frequency Results** plot located in the **Tabbed Documents** area.

<Figure
  figKey="run-the-bayesian"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure79.png"
  alt="Run the Bayesian Estimation Analysis."
  caption="Run the Bayesian Estimation Analysis."
/>

### Diagnose Convergence

After you have run the **Bayesian Estimation Analysis**, RMC-BestFit provides several useful plots for diagnosing the simulation convergence. The
default simulation option (see Simulation Options) will typically ensure that you get reasonable results.However, there may be situations where you
would like to adjust the simulation options to reduce runtimes while still achieving accurate results.

The **Bayesian Estimation Analysis** will open to the **Frequency Results** tab by default because this information is of most useful for a typical
user. However, let’s start from the bottom and work upward by first clicking on the **Markov Chain Traces** tab as shown in <FigReference figKey="markov-chain-traces" />.

#### Markov Chain Traces

Trace plots provide an important tool for assessing the mixing of a Markov chain. The trace plot is a time series plot of the Markov Chain iterations.
The trace plot shows the evolution of a parameter vector over the iterations of one or all chains. You can select the distribution parameter and
which chain(s) to view. In addition, you can include the warm up evolutions. Let’s select the **Skew (of log)(γ)** parameter and **All Chains** and check
the **Include Warm Up** checkbox, as shown in <FigReference figKey="markov-chain-traces" />.

We can see that for the first 100 or so evolutions, the sampler is warming up and has not yet converged. After that point, we see that the MCMC
sampler seems to be mixing well because all of the chains are exploring the same region of the parameter space.

What you want to look for is any anomaly in the traces. Are there any chains significantly different from the others? Is there multimodality? In other
words, do the traces jump from one modal region to another? These would be signs of poor mixing, and would indicate that you need to increase the
number of evolutions.

<Figure
  figKey="markov-chain-traces"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure80.png"
  alt="Markov Chain Traces."
  caption="Markov Chain Traces."
/>

#### Autocorrelation

Another way to check for convergence is to look at the autocorrelations between the MCMC samples. MCMC samples are dependent, so there will be
correlation among each consecutive iteration. This will not affect the validity of inference on the posterior samples so long as the sampler has time
to fully explore the posterior distribution. However, autocorrelation will affect the efficiency of the sampler. In other words, highly correlated
chains require more samples to produce the same level of precision for an estimate. Since autocorrelation tends to decrease as the lag increases,
thinning samples will reduce the final autocorrelation in the sample while also reducing the total number of saved MCMC iterations required.

Select the Autocorrelation tab and select the **Skew (of log)(γ)** parameter as shown in <FigReference figKey="autocorrelation" />. This plot shows the
lag-**_k_** autocorrelation between every sample and the sample **_k_** steps before. The autocorrelation should decrease as **_k_** increases. When
the autocorrelation is zero, the samples can be considered independent. Conversely, if the autocorrelation remains high for higher values of **_k_**,
then this indicates a high degree of correlation between samples and slow mixing.

The **Thinning Interval** is set to 20 by default in the simulation options. We can see that this ensures we get good mixing and near zero
autocorrelation.

<Figure
  figKey="autocorrelation"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure81.png"
  alt="Autocorrelation."
  caption="Autocorrelation."
/>

#### Mean Likelihood

Another way to check for convergence is to see if log-likelihood function is stable. Select the **Mean Likelihood** tab. We can see that during the
first 100 or so evolutions, the sampler is warming up and has not yet converged. As we previously saw in the Markov Chain trace plot, all of the
chains are exploring the same region of the parameter space, which leads to a very stable mean log-likelihood.

<Figure
  figKey="mean-likelihood"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure82.png"
  alt="Mean Likelihood."
  caption="Mean Likelihood."
/>

It is recommended that you do not rely on a single diagnostic measure. It is important to use a weight-of-evidence approach and view many different
diagnostics. After examining these plots, we can be confident that the MCMC simulation has converged. Now let’s explore the results.

### Explore Results

RMC-BestFit provides several tools for exploring the results of the Bayesian analysis. The **Bayesian Estimation Analysis** will open to the
**Frequency Results** tab by default as shown in <FigReference figKey="graphical-frequency-results" />.

#### Frequency Results

The posterior predictive distribution, posterior mode distribution, and the credible intervals will be plotted on the **Graphical Results** tab. By
default, the posterior parent distribution is plotted as a frequency curve, with annual exceedance probabilities plotted on the X-axis using a Normal
scale, and magnitude on the Y-axis using a logarithmic scale. You may edit the plot properties, flip the axes, or changing the axes scales as desired.
RMC-BestFit will save and persist all of the changes you have made to the plot.

<Figure
  figKey="graphical-frequency-results"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure83.png"
  alt="Graphical Frequency Results."
  caption="Graphical Frequency Results."
/>

Click the **Tabular Results** tab to view the frequency curve results and the posterior mode summary statistics as shown
in <FigReference figKey="tabular-frequency-results" />. All of the outputted posterior parameter sets and associated log-likelihood values are available
on the **Parameter Sets** tab as shown in <FigReference figKey="parameter-sets" />. You may sort these tables, and copy all of the values for external
use.

<Figure
  figKey="tabular-frequency-results"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure84.png"
  alt="Tabular Frequency Results."
  caption="Tabular Frequency Results."
/>

<Figure
  figKey="parameter-sets"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure85.png"
  alt="Parameter Sets."
  caption="Parameter Sets."
/>

#### Kernel Density

RMC-BestFit provides kernel density plots of the marginal posterior distribution of parameters. Kernel density estimates are closely related to
histograms, but provide smoothness and continuity. Select the **Kernel Density** tab, select the**Skew (of log)(γ)** parameter, and check the **Show
Prior Distribution** checkbox, as shown in <FigReference figKey="kernel-density" />. Recall that the prior for skew was set as a uniform
distribution <EquationNoRef equation="U(-2, +2)" />.

Underneath the plot, you can expand the **Summary Statistics** for the marginal distribution. Here we can see that the mean of the skew (of log)
parameter is -0.3337 with a standard deviation of 0.1756. You will also notice that there is a statistic labeled **Rhat**. This is often referred to
as the Gelman-Rubin statistic, which assesses the mixing of the Markov chains using the between- and within-chain
variances <Citation citationKey="Gelman2014" />. A Rhat equal to 1.0 indicates that the posterior distribution has likely converged.

<Figure
  figKey="kernel-density"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure86.png"
  alt="Kernel Density."
  caption="Kernel Density."
/>

#### Histogram

RMC-BestFit also provides histograms of the marginal posterior distribution of parameters. These plots provide the same information as the kernel
density plots. The histogram bins are set using the Rice rule <EquationNoRef equation="k = 2\sqrt[3]{n}" />, where <EquationNoRef equation="k" />
is the number of bins, and <EquationNoRef equation="n" /> is the number of posterior parameter sets.

<Figure
  figKey="histogram"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure87.png"
  alt="Histogram."
  caption="Histogram."
/>

#### Bivariate

RMC-BestFit provides the option to view the marginal posterior density functions for any pair of parameters as a two-dimensional heat map, with the
color red indicating the highest density and blue indicated lowest density. Bivariate plots illustrate the dependence among the parent distribution
parameters.

Typically, the higher order parameters are dependent on the lower order parameters. Set the **X Parameter** to be the **Std Dev (of log) (σ)** and
the **Y Parameter** to be **Skew (of log)(γ)**, as shown in <FigReference figKey="bivariate" />. We can see that standard deviation is negatively
correlated with skew. Smaller standard deviations result in higher skews; whereas higher standard deviations results in lower skews. This tradeoff
in parameters is typical with the LPIII distribution.

<Figure
  figKey="bivariate"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure88.png"
  alt="Bivariate."
  caption="Bivariate."
/>

### Informative Priors

An informative prior provides specific, scientific information about the parameter. Prior information can be obtained from regional analysis, causal
modeling, or expert elicitation. In flood frequency, an example of an informative prior would be the use of a regional skew <Citation citationKey="Kuczera1983" />
for the LPIII distribution as described in Bulletin 17B <Citation citationKey="USGS1982" /> and 17C <Citation citationKey="USGS2018" />.

For the Blakely Mountain Dam, regional skew information was obtained from a USGS regional study of Arkansas, Oklahoma, and Louisiana <Citation citationKey="Wagner2016" />.
From the USGS study, the regional skew was determined to be -0.17 with a mean-square error (MSE) of 0.12. This information can be incorporated into
the Bayesian analysis by setting the prior for the skew parameter of LPIII to be a Normal distribution with a mean of -0.17 and standard deviation
of 0.35, or <EquationNoRef equation="\sqrt{0.12}" />.

First, uncheck the **Use Default Flat Priors** checkbox located on the **General** tab of the **Properties Window**. Then, click the distribution
button for the skew (of log) parameter. A distribution selector will pop open to the left of the button, as shown in <FigReference figKey="informative-prior-on" />.

<Figure
  figKey="informative-prior-on"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure89.png"
  alt="Informative Prior on Skew."
  caption="Informative Prior on Skew."
/>

Next, select the Normal distribution and set the mean to be -0.17 and the standard deviation to be 0.35 as shown below.

<Figure
  figKey="select-distribution-for-skew"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure90.png"
  alt="Select Distribution for Skew."
  caption="Select Distribution for Skew."
/>

Click away from the distribution selector popup and it will automatically close. You will now see that the prior distribution for skew has been set
as <EquationNoRef equation="N(-0.17,0.35)" />. Now, click the **Estimate** command button to perform the Bayesian analysis using the informative prior.

<Figure
  figKey="prior-distributions-for-params"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure91.png"
  alt="Prior Distributions for Parameters."
  caption="Prior Distributions for Parameters."
/>

When the simulation is complete, click on the Kernel Density tab and select the **Skew (of log)(γ)** parameter. When we used the default flat prior,the
mean of the skew (of log) was -0.3337 with a standard deviation of 0.1756. Now, with the informative prior, we can see that the mean of the skew (of
log) is -0.3062 with a standard deviation of 0.1616. The inclusion of the regional skew information has made the skew parameter less negative and
reduced the variance.

As the sample size increases, the influence of the prior distribution on posterior inferences will decrease because the data likelihood will dominate.
Taking this into account, regional prior information is most valuable when the at-site sample sizes are small relative to the effective sample size
of the regional information.

<Figure
  figKey="view-results-of"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure92.png"
  alt="View Results of Using an Informative Prior."
  caption="View Results of Using an Informative Prior."
/>

#### Priors on Quantiles

Modeled rainfall-runoff results can be incorporated into the Bayesian analysis by defining a prior distribution for a flood quantile. This approach is
referred to as causal information expansion, which analyzes the generating mechanisms of floods in the catchment of interest <Citation citationKey="MerzBloschl2008" />.

A regional precipitation-frequency analysis was performed for the Blakely Mountain watershed, and 3-day basin-average rainfall-frequency events were
routed using a calibrated HEC-HMS model. The main benefit of modeling regional rainfall-frequency information is that available rainfall records are
often much longer than the at-site flood records. Therefore, the regional information combined with causal rainfall-runoff modeling can provide
important prior information on the flood quantiles.

##### Use Single Quantile

Prior distributions for flood quantiles can be set in one of two ways. First, check the **Enable Priors on Quantiles** checkbox located on the
**General** tab of the **Properties Window**. By default, the **Use Single Quantile** checkbox will also be checked. For more details on this single
quantile approach, please refer to <Citation citationKey="Viglione2013" /> and <Citation citationKey="Skahill2016" />.

From the analysis performed with HEC-HMS, the distribution of rainfall-runoff at the 1E-4 AEP was determined to be Normally distributed with a mean of
155,000 cfs and a standard deviation of 22,000 cfs. This rare AEP was selected because in order to add information to the fit, it needed to be rarer
than the paleoflood event, while not being so rare as to be overly influential.

Click the distribution button and a distribution selector will pop open to the left of the button as shown in <FigReference figKey="select-distribution-for-quantile" />.
The Normal distribution is the only option available for priors on quantiles. Next, set the mean to be 155,000 and the standard deviation to be 22,000.
Click away from the distribution selector popup and it will automatically close. Now, select the 0.0001 AEP as shown below
in <FigReference figKey="select-distribution-for-quantile" />.

<Figure
  figKey="select-distribution-for-quantile"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure93.png"
  alt="Select Distribution for a Quantile."
  caption="Select Distribution for a Quantile."
/>

You will now see that the prior distribution for the quantile has been set to <EquationNoRef equation="N(155000,22000)" />. Now, click the **Estimate**
command button to perform the Bayesian analysis using the informative quantile prior. When the analysis is complete, you will see the frequency curve
with credible intervals appear in the**Frequency Results** plot located in the **Tabbed Documents** area. The mean of the quantile prior will be
displayed as a green square, and the 5<sup>th</sup> and 95<sup>th</sup> percentiles of the prior will be shown as a vertical error bar, as shown
in <FigReference figKey="frequency-results-using-single" />.

<Figure
  figKey="prior-distributions-for-single"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure94.png"
  alt="Prior Distributions for a Single Quantile."
  caption="Prior Distributions for a Single Quantile."
/>

<Figure
  figKey="frequency-results-using-single"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure95.png"
  alt="Frequency Results Using a Prior Distribution for a Single Quantile."
  caption="Frequency Results Using a Prior Distribution for a Single Quantile."
/>

If we click on the Kernel Density tab and select the **Skew (of log)(γ)** parameter, we can see that the mean of the skew (of log) is -0.2384 with a
standard deviation of 0.1465. The inclusion of the causal rainfall-runoff information has made the skew parameter significantly less negative, reduced
the variance, and reduced the width of the resulting credible intervals of the **Frequency Results**.

<Figure
  figKey="summary-statistics-results-single"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure96.png"
  alt="Summary Statistics Results for the Skew Parameter after Using an Informative Prior on a Single Quantile."
  caption="Summary Statistics Results for the Skew Parameter after Using an Informative Prior on a Single Quantile."
/>

##### Use Multiple Quantiles

The final way to set prior distributions for flood quantiles is to uncheck the **Use Single Quantile** checkbox. This option for setting priors on
distribution quantiles follows the approach used in <Citation citationKey="ColesTawn1996" />. The number of quantile priors must be equal to the
number of distribution parameters. For example, for the LPIII distribution there must be three quantile priors.

In the single quantile approach shown above, the choice of AEP for the prior information has a large influence on the resulting fit and credible
intervals. If a more frequent quantile is chosen, such as 1E-2, more weight would be given to the historical and paleoflood data and the quantile
prior would have less influence on the fit. Whereas, the choice of the 1E-4 quantile gives significant weight to the prior. Choosing a rare quantile
implies that we have high confidence in the regional precipitation-frequency analysis and modeled rainfall-runoff results. In general, the rarer the
chosen quantile for the prior information, the more influence it will have on the posterior results.

As a general rule of thumb, if you are using NOAA Atlas 14 (A14, https://hdsc.nws.noaa.gov/hdsc/pfds/pfds_map_cont.html) precipitation-frequency data
with a three parameter distribution, such as LPIII, then you should enter quantile priors for 1E-1, 1E-2, and 1E-3. However, if you have performed a
custom regional precipitation-frequency analysis that is believed to be of higher quality than A14, you should enter priors for 1E-2, 1E-3, and 1E-4.

In the case of Blakely Mountain Dam, a custom regional analysis was performed for the nearby Trinity River Basin in Texas, which is described
in <Citation citationKey="MetStat2018" />. The regional frequency analysis performed for the Trinity River Basin also included the geographical region
where the Blakely Mountain watershed is located in Arkansas. This study incorporated advanced techniques, such as storm typing; therefore, the results
are considered to provide a better extrapolation to rare exceedance probabilities than A14.

Using the results from the HEC-HMS analysis, the distribution of rainfall-runoff for the 1E-2, 1E-3, and 1E-4 AEP quantiles are shown
in <FigReference figKey="prior-distributions-for-multiple" />. After you have entered these prior distributions, click the **Estimate** command button
to perform the Bayesian analysis. The **Frequency Results** plot is shown below in <FigReference figKey="frequency-results-using-multiple" />.

<Figure
  figKey="prior-distributions-for-multiple"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure97.png"
  alt="Prior Distributions for Multiple Quantiles."
  caption="Prior Distributions for Multiple Quantiles."
/>

<Figure
  figKey="frequency-results-using-multiple"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure98.png"
  alt="Frequency Results Using a Prior Distribution for Multiple Quantiles."
  caption="Frequency Results Using a Prior Distribution for Multiple Quantiles."
/>

If we click on the Kernel Density tab and select the **Skew (of log)(γ)** parameter, we can see that the mean of the skew (of log) is -0.2779 with a
standard deviation of 0.1500. The use of multiple quantiles has still made the skew parameter less negative and reduced the variance. However, the
effect is less noticeable as compared to what we saw with the single quantile option. With this in mind, the single quantile option has a potential to
underestimate the true parameter and quantile variance. The multiple quantile prior method provides a more complete treatment of the priors, and is
considered a better choice when the data is available.

<Figure
  figKey="summary-statistics-results-multiple"
  src="figures/desktop-applications/rmc-bestfit/users-guide/figure99.png"
  alt="Summary Statistics Results for the Skew Parameter after Using an Informative Prior on Multiple Quantiles."
  caption="Summary Statistics Results for the Skew Parameter after Using an Informative Prior on Multiple Quantiles."
/>

As we saw in the regional skew example, when the at-site sample size increases, the influence of the prior distribution on posterior will decrease
because the data likelihood will dominate. Taking this into account, prior information on quantiles is most valuable when the at-site sample sizes are
small relative to the effective sample size of the regional precipitation-frequency and causal rainfall-runoff information. For further information
on setting informative priors for quantiles, please see <Citation citationKey="ColesTawn1996" />, <Citation citationKey="Smith2005" />
, <Citation citationKey="Viglione2013" />, and <Citation citationKey="Skahill2016" />.

You have now finished the example application with RMC-BestFit. Save the project by selecting **File** > **Save**, or by clicking the **Save** button
on the main window **Tool Bar**.

<CitationFootnote />
